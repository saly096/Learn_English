import { useState, useRef, useCallback, useEffect } from 'react';

/**
 * å½•éŸ³çŠ¶æ€
 */
export type RecordingState = 'idle' | 'recording' | 'paused' | 'error';

/**
 * å½•éŸ³é”™è¯¯ç±»å‹
 */
export interface RecordingError {
	type: 'permission_denied' | 'not_supported' | 'unknown';
	message: string;
}

/**
 * å½•éŸ³ Hook è¿”å›å€¼
 */
export interface UseAudioRecorderReturn {
	state: RecordingState;
	error: RecordingError | null;
	duration: number;
	start: () => Promise<boolean>;
	stop: () => Promise<Blob | null>;
	pause: () => void;
	resume: () => void;
	isRecording: boolean;
	isPaused: boolean;
}

/**
 * éŸ³é¢‘å½•éŸ³ Hook
 * 
 * å°è£… MediaRecorder APIï¼Œæä¾›ï¼š
 * - æƒé™è¯·æ±‚å’Œé”™è¯¯å¤„ç†
 * - å½•éŸ³æ§åˆ¶ï¼ˆå¼€å§‹ã€åœæ­¢ã€æš‚åœã€æ¢å¤ï¼‰
 * - æ—¶é•¿ç»Ÿè®¡
 * - Blob æ•°æ®è¿”å›
 * 
 * @example
 * ```typescript
 * const { start, stop, isRecording, error } = useAudioRecorder();
 * 
 * // å¼€å§‹å½•éŸ³
 * const success = await start();
 * if (!success) {
 *   console.error('Failed to start:', error);
 * }
 * 
 * // åœæ­¢å½•éŸ³å¹¶è·å–éŸ³é¢‘æ•°æ®
 * const audioBlob = await stop();
 * ```
 */
export function useAudioRecorder(): UseAudioRecorderReturn {
	const [state, setState] = useState<RecordingState>('idle');
	const [error, setError] = useState<RecordingError | null>(null);
	const [duration, setDuration] = useState<number>(0);
	
	const mediaRecorderRef = useRef<MediaRecorder | null>(null);
	const audioChunksRef = useRef<Blob[]>([]);
	const streamRef = useRef<MediaStream | null>(null);
	const startTimeRef = useRef<number>(0);
	const durationIntervalRef = useRef<number | null>(null);

	/**
	 * æ¸…ç†èµ„æº
	 */
	const cleanup = useCallback(() => {
		// åœæ­¢å®šæ—¶å™¨
		if (durationIntervalRef.current) {
			clearInterval(durationIntervalRef.current);
			durationIntervalRef.current = null;
		}
		
		// åœæ­¢åª’ä½“æµ
		if (streamRef.current) {
			streamRef.current.getTracks().forEach(track => track.stop());
			streamRef.current = null;
		}
		
		// æ¸…ç©ºå½•éŸ³æ•°æ®
		audioChunksRef.current = [];
		mediaRecorderRef.current = null;
		setDuration(0);
	}, []);

	/**
	 * å¼€å§‹å½•éŸ³
	 */
	const start = useCallback(async (): Promise<boolean> => {
		// ğŸš¨ å¼ºåˆ¶æ¸…ç†ï¼Œé˜²æ­¢å¤šå®ä¾‹è¿è¡Œ
		if (mediaRecorderRef.current || streamRef.current) {
			console.warn('[useAudioRecorder] âš ï¸ Found active recorder/stream before start, forcing cleanup');
			cleanup();
		}

		try {
			// æ£€æŸ¥æµè§ˆå™¨æ”¯æŒ
			if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
				setError({
					type: 'not_supported',
					message: 'Your browser does not support audio recording',
				});
				setState('error');
				return false;
			}

			// æ£€æŸ¥å¯ç”¨çš„éº¦å…‹é£è®¾å¤‡
			console.log('[useAudioRecorder] Checking available devices...');
			try {
				const devices = await navigator.mediaDevices.enumerateDevices();
				const audioInputs = devices.filter(device => device.kind === 'audioinput');
				console.log('[useAudioRecorder] Available audio inputs:', audioInputs.length);
				
				if (audioInputs.length === 0) {
					setError({
						type: 'unknown',
						message: 'No microphone device found. Please connect a microphone and try again.',
					});
					setState('error');
					return false;
				}
				
				audioInputs.forEach((device, index) => {
					console.log(`  [${index}] ${device.label || 'Unnamed device'} (${device.deviceId})`);
				});
			} catch (devErr) {
				console.warn('[useAudioRecorder] Could not enumerate devices:', devErr);
			}

			console.log('[useAudioRecorder] Requesting microphone permission...');

			// è¯·æ±‚éº¦å…‹é£æƒé™
			let stream: MediaStream;
			try {
				// å°è¯•ä½¿ç”¨ç†æƒ³çš„éŸ³é¢‘è®¾ç½®
				stream = await navigator.mediaDevices.getUserMedia({ 
					audio: {
						echoCancellation: true,
						noiseSuppression: true,
						autoGainControl: true,
					}
				});
			} catch (err) {
				console.warn('[useAudioRecorder] Failed with constraints, trying basic audio...');
				// å¦‚æœå¤±è´¥ï¼Œä½¿ç”¨æœ€åŸºæœ¬çš„éŸ³é¢‘è®¾ç½®
				try {
					stream = await navigator.mediaDevices.getUserMedia({ audio: true });
				} catch (basicErr) {
					throw basicErr; // é‡æ–°æŠ›å‡ºï¼Œè®©å¤–å±‚ catch å¤„ç†
				}
			}

			console.log('[useAudioRecorder] Permission granted');
			streamRef.current = stream;

			// æ£€æµ‹æµè§ˆå™¨ç±»å‹
			const isSafari = /^((?!chrome|android).)*safari/i.test(navigator.userAgent);
			console.log('[useAudioRecorder] Browser detection:', { isSafari, userAgent: navigator.userAgent });

			// é€‰æ‹© MIME ç±»å‹
			let mimeType = '';
			if (isSafari) {
				// Safari/iOS ä¼˜å…ˆä½¿ç”¨ mp4
				if (MediaRecorder.isTypeSupported('audio/mp4')) {
					mimeType = 'audio/mp4';
				} else if (MediaRecorder.isTypeSupported('audio/aac')) {
					mimeType = 'audio/aac';
				} else if (MediaRecorder.isTypeSupported('audio/webm')) {
					mimeType = 'audio/webm'; // åªæœ‰å½“ mp4 ä¸æ”¯æŒæ—¶æ‰å°è¯• webm
				} else {
					console.warn('[useAudioRecorder] No supported MIME type found for Safari, trying default');
					mimeType = ''; // è®©æµè§ˆå™¨ä½¿ç”¨é»˜è®¤å€¼
				}
			} else {
				// Chrome/Firefox ä¼˜å…ˆä½¿ç”¨ webm
				if (MediaRecorder.isTypeSupported('audio/webm')) {
					mimeType = 'audio/webm';
				} else if (MediaRecorder.isTypeSupported('audio/webm;codecs=opus')) {
					mimeType = 'audio/webm;codecs=opus';
				} else if (MediaRecorder.isTypeSupported('audio/mp4')) {
					mimeType = 'audio/mp4';
				}
			}

			console.log('[useAudioRecorder] Selected MIME type:', mimeType || 'default');
			
			const options: MediaRecorderOptions = {
				audioBitsPerSecond: 128000,
			};
			if (mimeType) {
				options.mimeType = mimeType;
			}

			const mediaRecorder = new MediaRecorder(stream, options);

			mediaRecorderRef.current = mediaRecorder;
			audioChunksRef.current = [];

			// ç›‘å¬æ•°æ®
			mediaRecorder.ondataavailable = (event) => {
				if (event.data.size > 0) {
					audioChunksRef.current.push(event.data);
					console.log('[useAudioRecorder] Chunk received:', event.data.size, 'bytes');
				}
			};

			// ç›‘å¬é”™è¯¯
			mediaRecorder.onerror = (event) => {
				console.error('[useAudioRecorder] MediaRecorder error:', event);
				setError({
					type: 'unknown',
					message: 'Recording error occurred',
				});
				setState('error');
			};

			// å¼€å§‹å½•éŸ³
			mediaRecorder.start(100); // æ¯ 100ms æ”¶é›†ä¸€æ¬¡æ•°æ®
			startTimeRef.current = Date.now();
			setState('recording');
			setError(null);

			// å¯åŠ¨æ—¶é•¿ç»Ÿè®¡
			durationIntervalRef.current = window.setInterval(() => {
				const elapsed = (Date.now() - startTimeRef.current) / 1000;
				setDuration(elapsed);
			}, 100);

			console.log('[useAudioRecorder] Recording started');
			return true;

		} catch (err) {
			console.error('[useAudioRecorder] Failed to start recording:', err);

			// å¤„ç†ä¸åŒç±»å‹çš„é”™è¯¯
			if (err instanceof DOMException) {
				switch (err.name) {
					case 'NotAllowedError':
						setError({
							type: 'permission_denied',
							message: 'Microphone permission denied. Please allow microphone access in your browser settings.',
						});
						break;
					
					case 'NotFoundError':
						setError({
							type: 'unknown',
							message: 'No microphone found. Please:\n1. Connect a microphone\n2. Check Windows Sound settings\n3. Ensure microphone is not disabled',
						});
						break;
					
					case 'NotReadableError':
						setError({
							type: 'unknown',
							message: 'Microphone is being used by another application. Please close other apps using the microphone.',
						});
						break;
					
					case 'OverconstrainedError':
						setError({
							type: 'unknown',
							message: 'Microphone does not meet requirements. Trying with different settings...',
						});
						break;
					
					default:
						setError({
							type: 'unknown',
							message: `Microphone error: ${err.message || err.name}`,
						});
				}
			} else {
				setError({
					type: 'unknown',
					message: err instanceof Error ? err.message : 'Failed to start recording',
				});
			}

			setState('error');
			cleanup();
			return false;
		}
	}, [cleanup]);

	/**
	 * åœæ­¢å½•éŸ³
	 * @returns å½•éŸ³çš„ Blob å¯¹è±¡ï¼Œå¤±è´¥è¿”å› null
	 */
	const stop = useCallback(async (): Promise<Blob | null> => {
		return new Promise((resolve) => {
			const recorder = mediaRecorderRef.current;
			
			console.log('[useAudioRecorder] â¹ï¸ Stop requested, recorder:', {
				exists: !!recorder,
				state: recorder?.state,
				chunks: audioChunksRef.current.length
			});
			
			if (!recorder || recorder.state === 'inactive') {
				console.warn('[useAudioRecorder] No active recording');
				cleanup();
				setState('idle');
				resolve(null);
				return;
			}

			// çŠ¶æ€æ ‡å¿—ï¼Œé˜²æ­¢å¤šæ¬¡ resolveï¼ˆå…³é”®ï¼šé˜²æ­¢å¼‚æ­¥ç«æ€ï¼‰
			let isResolved = false;
			const stopRequested = true; // æ ‡è®°åœæ­¢å·²è¢«è¯·æ±‚

			// ç»Ÿä¸€çš„å®Œæˆå¤„ç†å‡½æ•°
			const finalize = () => {
				if (isResolved) return;
				isResolved = true;

				console.log('[useAudioRecorder] âœ… Finalizing recording...');
				
				// å†æ¬¡ç¡®ä¿æ‰€æœ‰è½¨é“åœæ­¢ï¼ˆåŒé‡ä¿é™©ï¼‰
				if (streamRef.current) {
					streamRef.current.getTracks().forEach(t => t.stop());
				}

				if (audioChunksRef.current.length === 0) {
					console.warn('[useAudioRecorder] No audio data recorded');
					cleanup();
					setState('idle');
					resolve(null);
					return;
				}

				// åˆå¹¶æ•°æ®
				const mimeType = recorder.mimeType;
				const audioBlob = new Blob(audioChunksRef.current, { type: mimeType });
				
				console.log('[useAudioRecorder] ğŸ“¦ Recording complete:', {
					size: audioBlob.size,
					type: audioBlob.type,
					duration: duration.toFixed(2) + 's',
					chunks: audioChunksRef.current.length,
				});

				cleanup();
				setState('idle');
				resolve(audioBlob);
			};
			
			// ç›‘å¬åœæ­¢äº‹ä»¶
			recorder.onstop = () => {
				console.log('[useAudioRecorder] ğŸ”” MediaRecorder onstop fired');
				finalize();
			};

			// æ›¿æ¢ ondataavailableï¼Œåœæ­¢åå¿½ç•¥æ•°æ®
			recorder.ondataavailable = (event) => {
				if (!stopRequested && event.data.size > 0) {
					audioChunksRef.current.push(event.data);
					console.log('[useAudioRecorder] Chunk received:', event.data.size, 'bytes');
				} else if (stopRequested) {
					console.log('[useAudioRecorder] âš ï¸ Ignoring chunk after stop:', event.data.size, 'bytes');
				}
			};

			// åœæ­¢å½•éŸ³
			try {
				console.log('[useAudioRecorder] ğŸ›‘ Stopping recorder state:', recorder.state);
				
				if (recorder.state === 'recording' || recorder.state === 'paused') {
					recorder.stop();
				}
				
				// ç«‹å³åœæ­¢è½¨é“
				if (streamRef.current) {
					console.log('[useAudioRecorder] ğŸ¤ Stopping media tracks...');
					streamRef.current.getTracks().forEach(track => track.stop());
				} else {
					// å°è¯•ä» recorder è·å– stream (å¤‡ç”¨)
					// @ts-ignore
					const recStream = recorder.stream;
					if (recStream && typeof recStream.getTracks === 'function') {
						console.log('[useAudioRecorder] ğŸ¤ Stopping tracks from recorder.stream...');
						recStream.getTracks().forEach((t: any) => t.stop());
					}
				}
				
				// è®¾ç½®è¶…æ—¶ä¿æŠ¤ (1ç§’)
				setTimeout(() => {
					if (!isResolved) {
						console.warn('[useAudioRecorder] â° Stop timeout triggered, forcing finalize');
						finalize();
					}
				}, 1000);
				
			} catch (error) {
				console.error('[useAudioRecorder] âŒ Error stopping recorder:', error);
				finalize(); // å‡ºé”™ä¹Ÿå¼ºåˆ¶å®Œæˆ
			}
		});
	}, [cleanup, duration]);

	/**
	 * æš‚åœå½•éŸ³
	 */
	const pause = useCallback(() => {
		const recorder = mediaRecorderRef.current;
		if (recorder && recorder.state === 'recording') {
			recorder.pause();
			setState('paused');
			
			// åœæ­¢æ—¶é•¿ç»Ÿè®¡
			if (durationIntervalRef.current) {
				clearInterval(durationIntervalRef.current);
				durationIntervalRef.current = null;
			}
			
			console.log('[useAudioRecorder] Recording paused');
		}
	}, []);

	/**
	 * æ¢å¤å½•éŸ³
	 */
	const resume = useCallback(() => {
		const recorder = mediaRecorderRef.current;
		if (recorder && recorder.state === 'paused') {
			recorder.resume();
			setState('recording');
			
			// æ¢å¤æ—¶é•¿ç»Ÿè®¡
			const pausedDuration = duration;
			startTimeRef.current = Date.now() - pausedDuration * 1000;
			durationIntervalRef.current = window.setInterval(() => {
				const elapsed = (Date.now() - startTimeRef.current) / 1000;
				setDuration(elapsed);
			}, 100);
			
			console.log('[useAudioRecorder] Recording resumed');
		}
	}, [duration]);

	// ç»„ä»¶å¸è½½æ—¶æ¸…ç†èµ„æºï¼ˆé˜²æ­¢å†…å­˜æ³„æ¼ï¼‰
	useEffect(() => {
		return () => {
			console.log('[useAudioRecorder] Component unmounting, cleaning up...');
			cleanup();
		};
	}, [cleanup]);

	return {
		state,
		error,
		duration,
		start,
		stop,
		pause,
		resume,
		isRecording: state === 'recording',
		isPaused: state === 'paused',
	};
}
